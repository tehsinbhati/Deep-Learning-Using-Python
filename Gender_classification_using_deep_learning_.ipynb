{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender classification using deep learning .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Gender Classification**"
      ],
      "metadata": {
        "id": "Npj3zbTkgLmc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K9OSJ_d7XjkG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gender - This is either \"Male\" or \"Female\".**\n",
        "\n",
        "Content\n",
        "This dataset contains 7 features and a label column.\n",
        "1.longhair - This column contains 0's and 1's where 1 is \"long hair\" and 0 is \"not long hair\".\n",
        "\n",
        "2.foreheadwidthcm - This column is in CM's. This is the width of the forehead.\n",
        "\n",
        "3.foreheadheightcm - This is the height of the forehead and it's in Cm's.\n",
        "\n",
        "4.nosewide - This column contains 0's and 1's where 1 is \"wide nose\" and 0 is \"not wide nose\".\n",
        "\n",
        "5.noselong - This column contains 0's and 1's where 1 is \"Long nose\" and 0 is \"not long nose\".\n",
        "\n",
        "6.lipsthin - This column contains 0's and 1's where 1 represents the \"thin lips\" while 0 is \"Not thin lips\".\n",
        "\n",
        "7.distancenosetoliplong - This column contains 0's and 1's where 1 represents the \"long distance between nose and lips\" while 0 is \"short distance between nose and lips\".\n",
        "\n"
      ],
      "metadata": {
        "id": "ydKhVYctfDqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To load the dataset\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/ItVedantPythonAWPClasswork/csv datasets/gender_classification_v7.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mPckgw2EXrcF",
        "outputId": "f74264b0-7999-44c9-c2bb-27be11adfbc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
              "0          1               11.8                 6.1          1          0   \n",
              "1          0               14.0                 5.4          0          0   \n",
              "2          0               11.8                 6.3          1          1   \n",
              "3          0               14.4                 6.1          0          1   \n",
              "4          1               13.5                 5.9          0          0   \n",
              "\n",
              "   lips_thin  distance_nose_to_lip_long  gender  \n",
              "0          1                          1    Male  \n",
              "1          1                          0  Female  \n",
              "2          1                          1    Male  \n",
              "3          1                          1    Male  \n",
              "4          0                          0  Female  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8da0307-495a-4b7c-9c6c-ab67e2e47b70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>long_hair</th>\n",
              "      <th>forehead_width_cm</th>\n",
              "      <th>forehead_height_cm</th>\n",
              "      <th>nose_wide</th>\n",
              "      <th>nose_long</th>\n",
              "      <th>lips_thin</th>\n",
              "      <th>distance_nose_to_lip_long</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.5</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8da0307-495a-4b7c-9c6c-ab67e2e47b70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8da0307-495a-4b7c-9c6c-ab67e2e47b70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8da0307-495a-4b7c-9c6c-ab67e2e47b70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLFDrjFEYSpi",
        "outputId": "1b2766be-15e5-4407-a99e-306b917a866f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5001, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qttktRBCYemW",
        "outputId": "a8a1cccb-2707-4af1-deb9-28bd7bf302ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "long_hair                    0\n",
              "forehead_width_cm            0\n",
              "forehead_height_cm           0\n",
              "nose_wide                    0\n",
              "nose_long                    0\n",
              "lips_thin                    0\n",
              "distance_nose_to_lip_long    0\n",
              "gender                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking type to confirm null values\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA1d5-N2YusK",
        "outputId": "14e8bce4-e9bc-40d5-94be-400a2fcdb7c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "long_hair                      int64\n",
              "forehead_width_cm            float64\n",
              "forehead_height_cm           float64\n",
              "nose_wide                      int64\n",
              "nose_long                      int64\n",
              "lips_thin                      int64\n",
              "distance_nose_to_lip_long      int64\n",
              "gender                        object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6keG80VY0kn",
        "outputId": "73f71f11-6559-4081-a64d-b582e32246ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1768"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Split DataSet into 2 parts\n",
        "# Numeric type and Categorical type\n",
        "df_num=df.select_dtypes(['int64','float64'])\n",
        "df_cat=df.select_dtypes(object)"
      ],
      "metadata": {
        "id": "bOaRCIYNY3_c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_num.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bW9Qd4hZby8a",
        "outputId": "8fe11938-6f4b-4546-bda6-c52ad7e7f1b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
              "0          1               11.8                 6.1          1          0   \n",
              "1          0               14.0                 5.4          0          0   \n",
              "2          0               11.8                 6.3          1          1   \n",
              "3          0               14.4                 6.1          0          1   \n",
              "4          1               13.5                 5.9          0          0   \n",
              "\n",
              "   lips_thin  distance_nose_to_lip_long  \n",
              "0          1                          1  \n",
              "1          1                          0  \n",
              "2          1                          1  \n",
              "3          1                          1  \n",
              "4          0                          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9df20891-6270-460c-85bd-1ca827335397\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>long_hair</th>\n",
              "      <th>forehead_width_cm</th>\n",
              "      <th>forehead_height_cm</th>\n",
              "      <th>nose_wide</th>\n",
              "      <th>nose_long</th>\n",
              "      <th>lips_thin</th>\n",
              "      <th>distance_nose_to_lip_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.5</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9df20891-6270-460c-85bd-1ca827335397')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9df20891-6270-460c-85bd-1ca827335397 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9df20891-6270-460c-85bd-1ca827335397');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TBsyJa0ub1Rg",
        "outputId": "d1fe2cac-fe2f-4292-97ad-f1cd781308af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender\n",
              "0    Male\n",
              "1  Female\n",
              "2    Male\n",
              "3    Male\n",
              "4  Female"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4a3c118-8447-4996-95ef-33b83fa06edf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4a3c118-8447-4996-95ef-33b83fa06edf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4a3c118-8447-4996-95ef-33b83fa06edf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4a3c118-8447-4996-95ef-33b83fa06edf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To convert categorical type data into numeric type.\n",
        "# Use Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "nS21Hgohb3v7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_cat:\n",
        "    # create an object of LabelEncoder\n",
        "    le=LabelEncoder()\n",
        "    df_cat[col]=le.fit_transform(df_cat[col])\n",
        "    "
      ],
      "metadata": {
        "id": "97bJMWlub6WH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qpmS0yemb9K6",
        "outputId": "f495db70-c25d-4169-e713-f156fb08929e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender\n",
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       1\n",
              "4       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d378f10-2d2e-40af-878b-ff08df30eb77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d378f10-2d2e-40af-878b-ff08df30eb77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d378f10-2d2e-40af-878b-ff08df30eb77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d378f10-2d2e-40af-878b-ff08df30eb77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxNVxfM_b_eW",
        "outputId": "2a777579-0436-49f3-f7f3-cb1543c93d0f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender    int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After applying LabelEncoder we concatenate df_cat and df_num.\n",
        "df_new=pd.concat([df_num,df_cat],axis=1)\n"
      ],
      "metadata": {
        "id": "G2TKNQ4vcBo9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0wKmFZHdcEeq",
        "outputId": "b77f0210-6fb9-4820-ba2a-3459cbf21328"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
              "0          1               11.8                 6.1          1          0   \n",
              "1          0               14.0                 5.4          0          0   \n",
              "2          0               11.8                 6.3          1          1   \n",
              "3          0               14.4                 6.1          0          1   \n",
              "4          1               13.5                 5.9          0          0   \n",
              "\n",
              "   lips_thin  distance_nose_to_lip_long  gender  \n",
              "0          1                          1       1  \n",
              "1          1                          0       0  \n",
              "2          1                          1       1  \n",
              "3          1                          1       1  \n",
              "4          0                          0       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a589b69-7b16-4e98-96a1-80a6568d700f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>long_hair</th>\n",
              "      <th>forehead_width_cm</th>\n",
              "      <th>forehead_height_cm</th>\n",
              "      <th>nose_wide</th>\n",
              "      <th>nose_long</th>\n",
              "      <th>lips_thin</th>\n",
              "      <th>distance_nose_to_lip_long</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.5</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a589b69-7b16-4e98-96a1-80a6568d700f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a589b69-7b16-4e98-96a1-80a6568d700f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a589b69-7b16-4e98-96a1-80a6568d700f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Select input and output\n",
        "X=df_new.drop('gender',axis=1)   # input \n",
        "Y=df_new['gender']               # output"
      ],
      "metadata": {
        "id": "vdMhlTd-cGnn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QtmlMSopcPYX",
        "outputId": "3f05f52a-00a6-4fb2-d913-8bec498f156a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
              "0          1               11.8                 6.1          1          0   \n",
              "1          0               14.0                 5.4          0          0   \n",
              "2          0               11.8                 6.3          1          1   \n",
              "3          0               14.4                 6.1          0          1   \n",
              "4          1               13.5                 5.9          0          0   \n",
              "\n",
              "   lips_thin  distance_nose_to_lip_long  \n",
              "0          1                          1  \n",
              "1          1                          0  \n",
              "2          1                          1  \n",
              "3          1                          1  \n",
              "4          0                          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad7bb13e-12e9-4a85-a4c8-f4b93508f6ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>long_hair</th>\n",
              "      <th>forehead_width_cm</th>\n",
              "      <th>forehead_height_cm</th>\n",
              "      <th>nose_wide</th>\n",
              "      <th>nose_long</th>\n",
              "      <th>lips_thin</th>\n",
              "      <th>distance_nose_to_lip_long</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.5</td>\n",
              "      <td>5.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad7bb13e-12e9-4a85-a4c8-f4b93508f6ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad7bb13e-12e9-4a85-a4c8-f4b93508f6ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad7bb13e-12e9-4a85-a4c8-f4b93508f6ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_5l-vDEcSPV",
        "outputId": "1b7b84e6-2569-4cf3-e750-1ce61fe104cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df_new,x='gender')\n",
        "f=df_new['gender'].value_counts()\n",
        "plt.yticks(f)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lQIupKRwcTl6",
        "outputId": "09d4dc9a-55d5-4445-a54a-c28d5a1a86ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,\n",
        "                                    random_state=1,stratify=Y)\n",
        "#stratify=output variablename"
      ],
      "metadata": {
        "id": "AV1tfHLPci8_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjojXWzocmXS",
        "outputId": "40cc1729-0b06-43ed-c31a-bdb736d06883"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1750\n",
              "1    1750\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ6EVdGxcp0J",
        "outputId": "53888dcd-3390-4988-b8e4-babe753e467b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    751\n",
              "1    750\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now applying Scaling on input data X_train and X_test before we train the model\n",
        "# Apply StandardScaler on input data training and testing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Create an object of StandardScaler class\n",
        "ss=StandardScaler()\n",
        "#means apply standard scaler for X_train and X_test data\n",
        "X_train=ss.fit_transform(X_train)\n",
        "X_test=ss.transform(X_test)"
      ],
      "metadata": {
        "id": "elCMIbC5cuW0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D57c-bescxHC",
        "outputId": "993015ff-fe1f-43e9-f760-68e533bca77d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3500, 7), (1501, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a architecture of neural network\n",
        "import tensorflow as tf\n",
        "#create a object of Sequential class\n",
        "model=tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(units=7,activation='relu',input_shape=(X.shape[1],)),\n",
        "       tf.keras.layers.Dense(units=7,activation='relu'),\n",
        "        tf.keras.layers.Dense(units=1,activation='sigmoid'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "9cyEMRu1cz1E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1DuJUfEc6UA",
        "outputId": "bbe43741-d2c4-4a52-9052-f6d3500d1d68"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120\n",
            "Trainable params: 120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-2X3Q0--c9vg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a procedure for callback(Earlystopping)\n",
        "#Early Stopping : \n",
        "#EarlyStopping : for decide epoch\n",
        "#create a procedure for callback \n",
        "from tensorflow.keras.callbacks import EarlyStopping             \n",
        "#create callback : -\n",
        "#EarlyStopping() inbuilt function\n",
        "cb=EarlyStopping(\n",
        "    monitor=\"val_loss\",  #val_loss means testing error\n",
        "    min_delta=0.00001, #value of lambda \n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    mode=\"auto\", #min loss \n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "1aomKiFPdBkJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to do validation"
      ],
      "metadata": {
        "id": "zUdp1JCwdJHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "#trained_model=model.fit(X_train,Y_train,epochs=4000,\n",
        "#                        validation_split=0.2,callbacks=cb)\n",
        "#validation_split=0.2 means take 20% data for validation from X_train,Y_train\n",
        "X_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "1Jp1iUhkdK2s"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model=model.fit(X_train,Y_train,epochs=4000,\n",
        "                        validation_data=(X_val,Y_val),callbacks=cb)\n",
        "#benifical to check which records have been chosen in x_val Y_val later\n",
        "#this is same as validation_split=0.2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqmPi0CodM_i",
        "outputId": "fde84cb4-be15-44c0-c623-2a01a970e2f1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4000\n",
            "88/88 [==============================] - 2s 9ms/step - loss: 0.5462 - accuracy: 0.7786 - val_loss: 0.4148 - val_accuracy: 0.9200\n",
            "Epoch 2/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.9439 - val_loss: 0.2070 - val_accuracy: 0.9529\n",
            "Epoch 3/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9589 - val_loss: 0.1228 - val_accuracy: 0.9614\n",
            "Epoch 4/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9621 - val_loss: 0.0973 - val_accuracy: 0.9600\n",
            "Epoch 5/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9654 - val_loss: 0.0876 - val_accuracy: 0.9614\n",
            "Epoch 6/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9661 - val_loss: 0.0830 - val_accuracy: 0.9614\n",
            "Epoch 7/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9671 - val_loss: 0.0810 - val_accuracy: 0.9614\n",
            "Epoch 8/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9679 - val_loss: 0.0796 - val_accuracy: 0.9614\n",
            "Epoch 9/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9675 - val_loss: 0.0787 - val_accuracy: 0.9629\n",
            "Epoch 10/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9686 - val_loss: 0.0783 - val_accuracy: 0.9629\n",
            "Epoch 11/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9682 - val_loss: 0.0778 - val_accuracy: 0.9629\n",
            "Epoch 12/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9696 - val_loss: 0.0778 - val_accuracy: 0.9614\n",
            "Epoch 13/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9682 - val_loss: 0.0778 - val_accuracy: 0.9614\n",
            "Epoch 14/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9689 - val_loss: 0.0773 - val_accuracy: 0.9643\n",
            "Epoch 15/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9689 - val_loss: 0.0775 - val_accuracy: 0.9643\n",
            "Epoch 16/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9700 - val_loss: 0.0769 - val_accuracy: 0.9643\n",
            "Epoch 17/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9689 - val_loss: 0.0767 - val_accuracy: 0.9643\n",
            "Epoch 18/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9693 - val_loss: 0.0766 - val_accuracy: 0.9643\n",
            "Epoch 19/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9696 - val_loss: 0.0763 - val_accuracy: 0.9643\n",
            "Epoch 20/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9696 - val_loss: 0.0762 - val_accuracy: 0.9643\n",
            "Epoch 21/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9700 - val_loss: 0.0761 - val_accuracy: 0.9643\n",
            "Epoch 22/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9707 - val_loss: 0.0759 - val_accuracy: 0.9643\n",
            "Epoch 23/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9700 - val_loss: 0.0758 - val_accuracy: 0.9671\n",
            "Epoch 24/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9707 - val_loss: 0.0758 - val_accuracy: 0.9671\n",
            "Epoch 25/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9693 - val_loss: 0.0753 - val_accuracy: 0.9671\n",
            "Epoch 26/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9711 - val_loss: 0.0755 - val_accuracy: 0.9671\n",
            "Epoch 27/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9696 - val_loss: 0.0755 - val_accuracy: 0.9671\n",
            "Epoch 28/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9704 - val_loss: 0.0753 - val_accuracy: 0.9671\n",
            "Epoch 29/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9704 - val_loss: 0.0750 - val_accuracy: 0.9671\n",
            "Epoch 30/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9707 - val_loss: 0.0749 - val_accuracy: 0.9671\n",
            "Epoch 31/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9700 - val_loss: 0.0747 - val_accuracy: 0.9671\n",
            "Epoch 32/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9707 - val_loss: 0.0749 - val_accuracy: 0.9671\n",
            "Epoch 33/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9704 - val_loss: 0.0746 - val_accuracy: 0.9671\n",
            "Epoch 34/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9700 - val_loss: 0.0753 - val_accuracy: 0.9671\n",
            "Epoch 35/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.0747 - val_accuracy: 0.9671\n",
            "Epoch 36/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9700 - val_loss: 0.0743 - val_accuracy: 0.9671\n",
            "Epoch 37/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9704 - val_loss: 0.0744 - val_accuracy: 0.9657\n",
            "Epoch 38/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9704 - val_loss: 0.0743 - val_accuracy: 0.9671\n",
            "Epoch 39/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9721 - val_loss: 0.0740 - val_accuracy: 0.9657\n",
            "Epoch 40/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9711 - val_loss: 0.0733 - val_accuracy: 0.9671\n",
            "Epoch 41/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9718 - val_loss: 0.0734 - val_accuracy: 0.9671\n",
            "Epoch 42/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9711 - val_loss: 0.0736 - val_accuracy: 0.9671\n",
            "Epoch 43/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9718 - val_loss: 0.0732 - val_accuracy: 0.9657\n",
            "Epoch 44/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 0.0736 - val_accuracy: 0.9657\n",
            "Epoch 45/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9714 - val_loss: 0.0733 - val_accuracy: 0.9657\n",
            "Epoch 46/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9714 - val_loss: 0.0732 - val_accuracy: 0.9671\n",
            "Epoch 47/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9700 - val_loss: 0.0735 - val_accuracy: 0.9657\n",
            "Epoch 48/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9711 - val_loss: 0.0738 - val_accuracy: 0.9657\n",
            "Epoch 49/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9711 - val_loss: 0.0738 - val_accuracy: 0.9657\n",
            "Epoch 50/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9711 - val_loss: 0.0739 - val_accuracy: 0.9657\n",
            "Epoch 51/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9714 - val_loss: 0.0738 - val_accuracy: 0.9671\n",
            "Epoch 52/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9718 - val_loss: 0.0734 - val_accuracy: 0.9657\n",
            "Epoch 53/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9707 - val_loss: 0.0738 - val_accuracy: 0.9657\n",
            "Epoch 54/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9721 - val_loss: 0.0736 - val_accuracy: 0.9643\n",
            "Epoch 55/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9714 - val_loss: 0.0736 - val_accuracy: 0.9657\n",
            "Epoch 56/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9718 - val_loss: 0.0735 - val_accuracy: 0.9657\n",
            "Epoch 57/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9714 - val_loss: 0.0733 - val_accuracy: 0.9657\n",
            "Epoch 58/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9718 - val_loss: 0.0735 - val_accuracy: 0.9643\n",
            "Epoch 59/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9718 - val_loss: 0.0733 - val_accuracy: 0.9657\n",
            "Epoch 60/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9725 - val_loss: 0.0730 - val_accuracy: 0.9657\n",
            "Epoch 61/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9725 - val_loss: 0.0726 - val_accuracy: 0.9657\n",
            "Epoch 62/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9721 - val_loss: 0.0729 - val_accuracy: 0.9657\n",
            "Epoch 63/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0688 - accuracy: 0.9725 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
            "Epoch 64/4000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 0.0727 - val_accuracy: 0.9657\n",
            "Epoch 65/4000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.0686 - accuracy: 0.9729 - val_loss: 0.0721 - val_accuracy: 0.9657\n",
            "Epoch 66/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0686 - accuracy: 0.9714 - val_loss: 0.0725 - val_accuracy: 0.9657\n",
            "Epoch 67/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9707 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
            "Epoch 68/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0683 - accuracy: 0.9721 - val_loss: 0.0722 - val_accuracy: 0.9657\n",
            "Epoch 69/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9732 - val_loss: 0.0720 - val_accuracy: 0.9657\n",
            "Epoch 70/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9729 - val_loss: 0.0722 - val_accuracy: 0.9657\n",
            "Epoch 71/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0681 - accuracy: 0.9714 - val_loss: 0.0723 - val_accuracy: 0.9657\n",
            "Epoch 72/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9725 - val_loss: 0.0718 - val_accuracy: 0.9657\n",
            "Epoch 73/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0680 - accuracy: 0.9721 - val_loss: 0.0722 - val_accuracy: 0.9657\n",
            "Epoch 74/4000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.0678 - accuracy: 0.9725 - val_loss: 0.0719 - val_accuracy: 0.9657\n",
            "Epoch 75/4000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0678 - accuracy: 0.9718 - val_loss: 0.0716 - val_accuracy: 0.9657\n",
            "Epoch 76/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9732 - val_loss: 0.0716 - val_accuracy: 0.9657\n",
            "Epoch 77/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0677 - accuracy: 0.9736 - val_loss: 0.0713 - val_accuracy: 0.9671\n",
            "Epoch 78/4000\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9721 - val_loss: 0.0709 - val_accuracy: 0.9657\n",
            "Epoch 79/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.0716 - val_accuracy: 0.9671\n",
            "Epoch 80/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9736 - val_loss: 0.0710 - val_accuracy: 0.9671\n",
            "Epoch 81/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9729 - val_loss: 0.0710 - val_accuracy: 0.9700\n",
            "Epoch 82/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9739 - val_loss: 0.0711 - val_accuracy: 0.9671\n",
            "Epoch 83/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9725 - val_loss: 0.0710 - val_accuracy: 0.9686\n",
            "Epoch 84/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9736 - val_loss: 0.0706 - val_accuracy: 0.9671\n",
            "Epoch 85/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9746 - val_loss: 0.0709 - val_accuracy: 0.9686\n",
            "Epoch 86/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9746 - val_loss: 0.0707 - val_accuracy: 0.9686\n",
            "Epoch 87/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.0711 - val_accuracy: 0.9686\n",
            "Epoch 88/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9739 - val_loss: 0.0708 - val_accuracy: 0.9686\n",
            "Epoch 89/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9739 - val_loss: 0.0707 - val_accuracy: 0.9686\n",
            "Epoch 90/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9750 - val_loss: 0.0707 - val_accuracy: 0.9686\n",
            "Epoch 91/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9746 - val_loss: 0.0711 - val_accuracy: 0.9686\n",
            "Epoch 92/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9743 - val_loss: 0.0707 - val_accuracy: 0.9686\n",
            "Epoch 93/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9739 - val_loss: 0.0705 - val_accuracy: 0.9686\n",
            "Epoch 94/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9739 - val_loss: 0.0708 - val_accuracy: 0.9686\n",
            "Epoch 95/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 0.0699 - val_accuracy: 0.9686\n",
            "Epoch 96/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9746 - val_loss: 0.0699 - val_accuracy: 0.9686\n",
            "Epoch 97/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9743 - val_loss: 0.0699 - val_accuracy: 0.9686\n",
            "Epoch 98/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0659 - accuracy: 0.9743 - val_loss: 0.0699 - val_accuracy: 0.9686\n",
            "Epoch 99/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0657 - accuracy: 0.9736 - val_loss: 0.0699 - val_accuracy: 0.9686\n",
            "Epoch 100/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9739 - val_loss: 0.0697 - val_accuracy: 0.9700\n",
            "Epoch 101/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9750 - val_loss: 0.0696 - val_accuracy: 0.9700\n",
            "Epoch 102/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9743 - val_loss: 0.0696 - val_accuracy: 0.9700\n",
            "Epoch 103/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9736 - val_loss: 0.0696 - val_accuracy: 0.9700\n",
            "Epoch 104/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9750 - val_loss: 0.0699 - val_accuracy: 0.9700\n",
            "Epoch 105/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9754 - val_loss: 0.0702 - val_accuracy: 0.9686\n",
            "Epoch 106/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9754 - val_loss: 0.0701 - val_accuracy: 0.9686\n",
            "Epoch 107/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9739 - val_loss: 0.0699 - val_accuracy: 0.9700\n",
            "Epoch 108/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9750 - val_loss: 0.0699 - val_accuracy: 0.9671\n",
            "Epoch 109/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9750 - val_loss: 0.0697 - val_accuracy: 0.9700\n",
            "Epoch 110/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9739 - val_loss: 0.0697 - val_accuracy: 0.9686\n",
            "Epoch 111/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9750 - val_loss: 0.0695 - val_accuracy: 0.9700\n",
            "Epoch 112/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9754 - val_loss: 0.0695 - val_accuracy: 0.9700\n",
            "Epoch 113/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9743 - val_loss: 0.0697 - val_accuracy: 0.9671\n",
            "Epoch 114/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9739 - val_loss: 0.0695 - val_accuracy: 0.9671\n",
            "Epoch 115/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9746 - val_loss: 0.0695 - val_accuracy: 0.9671\n",
            "Epoch 116/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9746 - val_loss: 0.0698 - val_accuracy: 0.9671\n",
            "Epoch 117/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9743 - val_loss: 0.0697 - val_accuracy: 0.9671\n",
            "Epoch 118/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 0.9750 - val_loss: 0.0693 - val_accuracy: 0.9700\n",
            "Epoch 119/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9732 - val_loss: 0.0691 - val_accuracy: 0.9686\n",
            "Epoch 120/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9743 - val_loss: 0.0693 - val_accuracy: 0.9686\n",
            "Epoch 121/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9746 - val_loss: 0.0690 - val_accuracy: 0.9686\n",
            "Epoch 122/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9746 - val_loss: 0.0690 - val_accuracy: 0.9671\n",
            "Epoch 123/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9743 - val_loss: 0.0691 - val_accuracy: 0.9671\n",
            "Epoch 124/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.0692 - val_accuracy: 0.9671\n",
            "Epoch 125/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9746 - val_loss: 0.0694 - val_accuracy: 0.9671\n",
            "Epoch 126/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9739 - val_loss: 0.0689 - val_accuracy: 0.9686\n",
            "Epoch 127/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9739 - val_loss: 0.0688 - val_accuracy: 0.9686\n",
            "Epoch 128/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9757 - val_loss: 0.0690 - val_accuracy: 0.9686\n",
            "Epoch 129/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9746 - val_loss: 0.0686 - val_accuracy: 0.9729\n",
            "Epoch 130/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9743 - val_loss: 0.0687 - val_accuracy: 0.9686\n",
            "Epoch 131/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0645 - accuracy: 0.9743 - val_loss: 0.0689 - val_accuracy: 0.9686\n",
            "Epoch 132/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9746 - val_loss: 0.0686 - val_accuracy: 0.9729\n",
            "Epoch 133/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9739 - val_loss: 0.0687 - val_accuracy: 0.9714\n",
            "Epoch 134/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9750 - val_loss: 0.0685 - val_accuracy: 0.9700\n",
            "Epoch 135/4000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0648 - accuracy: 0.9736 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 136/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9736 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 137/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9750 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 138/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9739 - val_loss: 0.0688 - val_accuracy: 0.9700\n",
            "Epoch 139/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9746 - val_loss: 0.0686 - val_accuracy: 0.9671\n",
            "Epoch 140/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9750 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 141/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9746 - val_loss: 0.0688 - val_accuracy: 0.9714\n",
            "Epoch 142/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9743 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 143/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9739 - val_loss: 0.0683 - val_accuracy: 0.9700\n",
            "Epoch 144/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9736 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 145/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9746 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 146/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9739 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 147/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9750 - val_loss: 0.0688 - val_accuracy: 0.9700\n",
            "Epoch 148/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9743 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 149/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9736 - val_loss: 0.0692 - val_accuracy: 0.9700\n",
            "Epoch 150/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9743 - val_loss: 0.0688 - val_accuracy: 0.9714\n",
            "Epoch 151/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9750 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 152/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9743 - val_loss: 0.0684 - val_accuracy: 0.9700\n",
            "Epoch 153/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9746 - val_loss: 0.0688 - val_accuracy: 0.9700\n",
            "Epoch 154/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9739 - val_loss: 0.0684 - val_accuracy: 0.9700\n",
            "Epoch 155/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9750 - val_loss: 0.0685 - val_accuracy: 0.9700\n",
            "Epoch 156/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9743 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 157/4000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0641 - accuracy: 0.9743 - val_loss: 0.0684 - val_accuracy: 0.9700\n",
            "Epoch 158/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.0640 - accuracy: 0.9736 - val_loss: 0.0690 - val_accuracy: 0.9700\n",
            "Epoch 159/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0644 - accuracy: 0.9746 - val_loss: 0.0685 - val_accuracy: 0.9686\n",
            "Epoch 160/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9739 - val_loss: 0.0685 - val_accuracy: 0.9700\n",
            "Epoch 161/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0639 - accuracy: 0.9743 - val_loss: 0.0683 - val_accuracy: 0.9700\n",
            "Epoch 162/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9750 - val_loss: 0.0680 - val_accuracy: 0.9700\n",
            "Epoch 163/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0687 - val_accuracy: 0.9700\n",
            "Epoch 164/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9754 - val_loss: 0.0682 - val_accuracy: 0.9700\n",
            "Epoch 165/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9739 - val_loss: 0.0682 - val_accuracy: 0.9700\n",
            "Epoch 166/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9743 - val_loss: 0.0682 - val_accuracy: 0.9700\n",
            "Epoch 167/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9754 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
            "Epoch 168/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9757 - val_loss: 0.0686 - val_accuracy: 0.9686\n",
            "Epoch 169/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9746 - val_loss: 0.0684 - val_accuracy: 0.9686\n",
            "Epoch 170/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9743 - val_loss: 0.0681 - val_accuracy: 0.9686\n",
            "Epoch 171/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9750 - val_loss: 0.0680 - val_accuracy: 0.9700\n",
            "Epoch 172/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9746 - val_loss: 0.0683 - val_accuracy: 0.9700\n",
            "Epoch 173/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 0.0682 - val_accuracy: 0.9700\n",
            "Epoch 174/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9736 - val_loss: 0.0679 - val_accuracy: 0.9700\n",
            "Epoch 175/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9750 - val_loss: 0.0679 - val_accuracy: 0.9686\n",
            "Epoch 176/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9754 - val_loss: 0.0675 - val_accuracy: 0.9686\n",
            "Epoch 177/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9757 - val_loss: 0.0681 - val_accuracy: 0.9686\n",
            "Epoch 178/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9761 - val_loss: 0.0681 - val_accuracy: 0.9686\n",
            "Epoch 179/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9750 - val_loss: 0.0681 - val_accuracy: 0.9686\n",
            "Epoch 180/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9746 - val_loss: 0.0680 - val_accuracy: 0.9700\n",
            "Epoch 181/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9743 - val_loss: 0.0674 - val_accuracy: 0.9700\n",
            "Epoch 182/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9750 - val_loss: 0.0676 - val_accuracy: 0.9700\n",
            "Epoch 183/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9732 - val_loss: 0.0679 - val_accuracy: 0.9700\n",
            "Epoch 184/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9754 - val_loss: 0.0677 - val_accuracy: 0.9700\n",
            "Epoch 185/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9739 - val_loss: 0.0674 - val_accuracy: 0.9700\n",
            "Epoch 186/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9757 - val_loss: 0.0678 - val_accuracy: 0.9686\n",
            "Epoch 187/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9746 - val_loss: 0.0674 - val_accuracy: 0.9700\n",
            "Epoch 188/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9754 - val_loss: 0.0675 - val_accuracy: 0.9700\n",
            "Epoch 189/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9754 - val_loss: 0.0676 - val_accuracy: 0.9700\n",
            "Epoch 190/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9761 - val_loss: 0.0673 - val_accuracy: 0.9686\n",
            "Epoch 191/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9743 - val_loss: 0.0673 - val_accuracy: 0.9700\n",
            "Epoch 192/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9743 - val_loss: 0.0672 - val_accuracy: 0.9686\n",
            "Epoch 193/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9739 - val_loss: 0.0675 - val_accuracy: 0.9700\n",
            "Epoch 194/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9746 - val_loss: 0.0674 - val_accuracy: 0.9686\n",
            "Epoch 195/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9754 - val_loss: 0.0670 - val_accuracy: 0.9686\n",
            "Epoch 196/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9750 - val_loss: 0.0670 - val_accuracy: 0.9700\n",
            "Epoch 197/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9743 - val_loss: 0.0670 - val_accuracy: 0.9686\n",
            "Epoch 198/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9743 - val_loss: 0.0667 - val_accuracy: 0.9686\n",
            "Epoch 199/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9739 - val_loss: 0.0668 - val_accuracy: 0.9686\n",
            "Epoch 200/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9746 - val_loss: 0.0664 - val_accuracy: 0.9686\n",
            "Epoch 201/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9750 - val_loss: 0.0670 - val_accuracy: 0.9686\n",
            "Epoch 202/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9746 - val_loss: 0.0664 - val_accuracy: 0.9700\n",
            "Epoch 203/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9750 - val_loss: 0.0665 - val_accuracy: 0.9686\n",
            "Epoch 204/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9746 - val_loss: 0.0661 - val_accuracy: 0.9686\n",
            "Epoch 205/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9757 - val_loss: 0.0662 - val_accuracy: 0.9686\n",
            "Epoch 206/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 0.0659 - val_accuracy: 0.9686\n",
            "Epoch 207/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9757 - val_loss: 0.0660 - val_accuracy: 0.9700\n",
            "Epoch 208/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 0.0660 - val_accuracy: 0.9686\n",
            "Epoch 209/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9729 - val_loss: 0.0659 - val_accuracy: 0.9686\n",
            "Epoch 210/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 0.0654 - val_accuracy: 0.9686\n",
            "Epoch 211/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 0.0657 - val_accuracy: 0.9686\n",
            "Epoch 212/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9746 - val_loss: 0.0655 - val_accuracy: 0.9686\n",
            "Epoch 213/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9746 - val_loss: 0.0655 - val_accuracy: 0.9686\n",
            "Epoch 214/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9743 - val_loss: 0.0650 - val_accuracy: 0.9700\n",
            "Epoch 215/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9757 - val_loss: 0.0653 - val_accuracy: 0.9686\n",
            "Epoch 216/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9743 - val_loss: 0.0651 - val_accuracy: 0.9686\n",
            "Epoch 217/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9750 - val_loss: 0.0649 - val_accuracy: 0.9686\n",
            "Epoch 218/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.0651 - val_accuracy: 0.9686\n",
            "Epoch 219/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.0647 - val_accuracy: 0.9686\n",
            "Epoch 220/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9768 - val_loss: 0.0650 - val_accuracy: 0.9686\n",
            "Epoch 221/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9754 - val_loss: 0.0650 - val_accuracy: 0.9686\n",
            "Epoch 222/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9754 - val_loss: 0.0652 - val_accuracy: 0.9714\n",
            "Epoch 223/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9750 - val_loss: 0.0650 - val_accuracy: 0.9686\n",
            "Epoch 224/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9754 - val_loss: 0.0653 - val_accuracy: 0.9686\n",
            "Epoch 225/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9757 - val_loss: 0.0649 - val_accuracy: 0.9671\n",
            "Epoch 226/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9754 - val_loss: 0.0650 - val_accuracy: 0.9700\n",
            "Epoch 227/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9750 - val_loss: 0.0646 - val_accuracy: 0.9686\n",
            "Epoch 228/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9757 - val_loss: 0.0645 - val_accuracy: 0.9700\n",
            "Epoch 229/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9743 - val_loss: 0.0643 - val_accuracy: 0.9729\n",
            "Epoch 230/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.0648 - val_accuracy: 0.9686\n",
            "Epoch 231/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9761 - val_loss: 0.0647 - val_accuracy: 0.9700\n",
            "Epoch 232/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9757 - val_loss: 0.0645 - val_accuracy: 0.9729\n",
            "Epoch 233/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9746 - val_loss: 0.0645 - val_accuracy: 0.9686\n",
            "Epoch 234/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9746 - val_loss: 0.0640 - val_accuracy: 0.9671\n",
            "Epoch 235/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9750 - val_loss: 0.0643 - val_accuracy: 0.9671\n",
            "Epoch 236/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9764 - val_loss: 0.0643 - val_accuracy: 0.9671\n",
            "Epoch 237/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9746 - val_loss: 0.0641 - val_accuracy: 0.9686\n",
            "Epoch 238/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9764 - val_loss: 0.0641 - val_accuracy: 0.9686\n",
            "Epoch 239/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9761 - val_loss: 0.0639 - val_accuracy: 0.9671\n",
            "Epoch 240/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9761 - val_loss: 0.0641 - val_accuracy: 0.9671\n",
            "Epoch 241/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9757 - val_loss: 0.0637 - val_accuracy: 0.9671\n",
            "Epoch 242/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.0639 - val_accuracy: 0.9671\n",
            "Epoch 243/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9754 - val_loss: 0.0636 - val_accuracy: 0.9686\n",
            "Epoch 244/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9761 - val_loss: 0.0641 - val_accuracy: 0.9686\n",
            "Epoch 245/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9754 - val_loss: 0.0639 - val_accuracy: 0.9700\n",
            "Epoch 246/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9764 - val_loss: 0.0637 - val_accuracy: 0.9671\n",
            "Epoch 247/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9764 - val_loss: 0.0638 - val_accuracy: 0.9671\n",
            "Epoch 248/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9761 - val_loss: 0.0641 - val_accuracy: 0.9671\n",
            "Epoch 249/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9754 - val_loss: 0.0636 - val_accuracy: 0.9671\n",
            "Epoch 250/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 0.0634 - val_accuracy: 0.9671\n",
            "Epoch 251/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9739 - val_loss: 0.0633 - val_accuracy: 0.9714\n",
            "Epoch 252/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.0632 - val_accuracy: 0.9671\n",
            "Epoch 253/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9764 - val_loss: 0.0633 - val_accuracy: 0.9671\n",
            "Epoch 254/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 0.0637 - val_accuracy: 0.9671\n",
            "Epoch 255/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9761 - val_loss: 0.0634 - val_accuracy: 0.9686\n",
            "Epoch 256/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 0.0633 - val_accuracy: 0.9686\n",
            "Epoch 257/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.0632 - val_accuracy: 0.9686\n",
            "Epoch 258/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9768 - val_loss: 0.0630 - val_accuracy: 0.9686\n",
            "Epoch 259/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9768 - val_loss: 0.0631 - val_accuracy: 0.9686\n",
            "Epoch 260/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9757 - val_loss: 0.0621 - val_accuracy: 0.9700\n",
            "Epoch 261/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9757 - val_loss: 0.0629 - val_accuracy: 0.9686\n",
            "Epoch 262/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.0627 - val_accuracy: 0.9686\n",
            "Epoch 263/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9761 - val_loss: 0.0629 - val_accuracy: 0.9671\n",
            "Epoch 264/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9771 - val_loss: 0.0627 - val_accuracy: 0.9686\n",
            "Epoch 265/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9764 - val_loss: 0.0627 - val_accuracy: 0.9686\n",
            "Epoch 266/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9764 - val_loss: 0.0629 - val_accuracy: 0.9671\n",
            "Epoch 267/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9761 - val_loss: 0.0625 - val_accuracy: 0.9714\n",
            "Epoch 268/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9764 - val_loss: 0.0625 - val_accuracy: 0.9686\n",
            "Epoch 269/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9761 - val_loss: 0.0628 - val_accuracy: 0.9686\n",
            "Epoch 270/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9761 - val_loss: 0.0625 - val_accuracy: 0.9714\n",
            "Epoch 271/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9768 - val_loss: 0.0626 - val_accuracy: 0.9671\n",
            "Epoch 272/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9761 - val_loss: 0.0626 - val_accuracy: 0.9686\n",
            "Epoch 273/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9764 - val_loss: 0.0622 - val_accuracy: 0.9714\n",
            "Epoch 274/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9764 - val_loss: 0.0626 - val_accuracy: 0.9686\n",
            "Epoch 275/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9764 - val_loss: 0.0621 - val_accuracy: 0.9714\n",
            "Epoch 276/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 0.0623 - val_accuracy: 0.9729\n",
            "Epoch 277/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9768 - val_loss: 0.0629 - val_accuracy: 0.9671\n",
            "Epoch 278/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9764 - val_loss: 0.0624 - val_accuracy: 0.9686\n",
            "Epoch 279/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9764 - val_loss: 0.0624 - val_accuracy: 0.9686\n",
            "Epoch 280/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9761 - val_loss: 0.0621 - val_accuracy: 0.9700\n",
            "Epoch 281/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9761 - val_loss: 0.0625 - val_accuracy: 0.9729\n",
            "Epoch 282/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9771 - val_loss: 0.0625 - val_accuracy: 0.9686\n",
            "Epoch 283/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9754 - val_loss: 0.0625 - val_accuracy: 0.9686\n",
            "Epoch 284/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9775 - val_loss: 0.0623 - val_accuracy: 0.9700\n",
            "Epoch 285/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9761 - val_loss: 0.0621 - val_accuracy: 0.9700\n",
            "Epoch 286/4000\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 0.0631 - val_accuracy: 0.9686\n",
            "Epoch 287/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 0.0623 - val_accuracy: 0.9700\n",
            "Epoch 288/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9775 - val_loss: 0.0626 - val_accuracy: 0.9700\n",
            "Epoch 289/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9754 - val_loss: 0.0624 - val_accuracy: 0.9729\n",
            "Epoch 290/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9775 - val_loss: 0.0624 - val_accuracy: 0.9729\n",
            "Epoch 291/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9771 - val_loss: 0.0626 - val_accuracy: 0.9686\n",
            "Epoch 292/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9768 - val_loss: 0.0622 - val_accuracy: 0.9686\n",
            "Epoch 293/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9764 - val_loss: 0.0628 - val_accuracy: 0.9686\n",
            "Epoch 294/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9761 - val_loss: 0.0630 - val_accuracy: 0.9671\n",
            "Epoch 295/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 0.0625 - val_accuracy: 0.9686\n",
            "Epoch 296/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9771 - val_loss: 0.0622 - val_accuracy: 0.9686\n",
            "Epoch 297/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9768 - val_loss: 0.0623 - val_accuracy: 0.9714\n",
            "Epoch 298/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9768 - val_loss: 0.0626 - val_accuracy: 0.9686\n",
            "Epoch 299/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9764 - val_loss: 0.0627 - val_accuracy: 0.9700\n",
            "Epoch 300/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9771 - val_loss: 0.0632 - val_accuracy: 0.9686\n",
            "Epoch 300: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loss and training score \n",
        "model.evaluate(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ_L8H20dPr5",
        "outputId": "279f4e3e-35c9-405b-a324-6eefd536474d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.059949424117803574, 0.9782142639160156]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing loss and testing score \n",
        "model.evaluate(X_val,Y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw2-rTMfdVNT",
        "outputId": "8bbb43fb-9b4e-4db8-a33d-7d02dc2fba9d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06321437656879425, 0.9685714244842529]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualise the loss(training loss) and val_loss(testing loss)\n",
        "plt.plot(trained_model.history['loss'],color='red',label='Traning Loss')\n",
        "plt.plot(trained_model.history['val_loss'],color='green',label='Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "YYq2edJMdXLw",
        "outputId": "c0e40634-7d53-40e7-c5d7-bf316a0c26d5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualise the loss(training loss) and val_loss(testing loss)\n",
        "plt.plot(trained_model.history['accuracy'],color='blue',label='Traning accuracy')\n",
        "plt.plot(trained_model.history['val_accuracy'],color='yellow',label='Testing val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RcJDnEU7dZN4",
        "outputId": "99fd52b3-3dbd-454e-88e3-2505ad3a0759"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model with 30% data \n",
        "Y_pred=model.predict(X_test).round(2) #gives the probability value of each class \n",
        "#for each row\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXHoxAaZdi5Q",
        "outputId": "402e1066-414c-4dd5-c63f-e97a614e968a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  ],\n",
              "       [0.01],\n",
              "       [0.01],\n",
              "       ...,\n",
              "       [0.18],\n",
              "       [0.  ],\n",
              "       [0.43]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=np.where(Y_pred>=0.5,1,0)\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXFsH-EndmDV",
        "outputId": "9e5ba64a-e6a2-4073-efe9-65f4213e624f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate classification report and confusion martix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "print(confusion_matrix(Y_test,Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6BrQT_Wdmwm",
        "outputId": "ee44a6a3-a71f-4296-d03b-59ac98ddb1ac"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       751\n",
            "           1       0.99      0.97      0.98       750\n",
            "\n",
            "    accuracy                           0.98      1501\n",
            "   macro avg       0.98      0.98      0.98      1501\n",
            "weighted avg       0.98      0.98      0.98      1501\n",
            "\n",
            "[[740  11]\n",
            " [ 24 726]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop-out : similar work as ensembling technique, random forest in ML\n",
        "#dropout mainly used to reduce overfitting of model.\n",
        "#20% to 50% note more than 50 not less than 20 on hidden layers only\n",
        "\n",
        "#create a architecture of neural network\n",
        "\n",
        "model=tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(units=7,activation='relu',input_shape=(X.shape[1],)),\n",
        "      tf.keras.layers.Dropout(0.2), #apply dropout on 1st hidden layer\n",
        "      tf.keras.layers.Dense(units=7,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2), #apply dropout on 2nd hidden layer\n",
        "      tf.keras.layers.Dense(units=7,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2), #apply dropout on 3rd hidden layer\n",
        "      tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "qpKKJ7QTdmy6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIB7lVOudm2c",
        "outputId": "9f2b7534-db3a-4116-ab25-4d482c61bc87"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 176\n",
            "Trainable params: 176\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yFFNPdPndnGu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a procedure for callback(Earlystopping)\n",
        "#Early Stopping : \n",
        "#EarlyStopping : for decide epoch\n",
        "#create a procedure for callback \n",
        "from tensorflow.keras.callbacks import EarlyStopping             \n",
        "#create callback : -\n",
        "#EarlyStopping() inbuilt function\n",
        "cb=EarlyStopping(\n",
        "    monitor=\"val_loss\",  #val_loss means testing error\n",
        "    min_delta=0.00001, #value of lambda \n",
        "    patience=20,\n",
        "    verbose=1,\n",
        "    mode=\"auto\", #min loss \n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")"
      ],
      "metadata": {
        "id": "Jb5lHuIqeMkR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model=model.fit(X_train,Y_train,epochs=4000,\n",
        "                        validation_data=(X_val,Y_val),callbacks=cb)\n",
        "#benifical to check which records have been chosen in x_val Y_val later\n",
        "#this is same as validation_split=0.2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSN3s9F_eO75",
        "outputId": "8a39dde2-0c67-4b90-9f86-86bd8b580da0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4000\n",
            "88/88 [==============================] - 2s 8ms/step - loss: 0.6561 - accuracy: 0.5904 - val_loss: 0.5398 - val_accuracy: 0.8686\n",
            "Epoch 2/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7936 - val_loss: 0.2913 - val_accuracy: 0.9257\n",
            "Epoch 3/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8504 - val_loss: 0.1677 - val_accuracy: 0.9457\n",
            "Epoch 4/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.8861 - val_loss: 0.1208 - val_accuracy: 0.9571\n",
            "Epoch 5/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9175 - val_loss: 0.1005 - val_accuracy: 0.9586\n",
            "Epoch 6/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9250 - val_loss: 0.0930 - val_accuracy: 0.9614\n",
            "Epoch 7/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1863 - accuracy: 0.9196 - val_loss: 0.0887 - val_accuracy: 0.9629\n",
            "Epoch 8/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9279 - val_loss: 0.0859 - val_accuracy: 0.9629\n",
            "Epoch 9/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9482 - val_loss: 0.0849 - val_accuracy: 0.9629\n",
            "Epoch 10/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9446 - val_loss: 0.0826 - val_accuracy: 0.9629\n",
            "Epoch 11/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9482 - val_loss: 0.0828 - val_accuracy: 0.9629\n",
            "Epoch 12/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9489 - val_loss: 0.0832 - val_accuracy: 0.9629\n",
            "Epoch 13/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9539 - val_loss: 0.0813 - val_accuracy: 0.9657\n",
            "Epoch 14/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9596 - val_loss: 0.0807 - val_accuracy: 0.9629\n",
            "Epoch 15/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9557 - val_loss: 0.0803 - val_accuracy: 0.9657\n",
            "Epoch 16/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9568 - val_loss: 0.0782 - val_accuracy: 0.9657\n",
            "Epoch 17/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9575 - val_loss: 0.0772 - val_accuracy: 0.9643\n",
            "Epoch 18/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9596 - val_loss: 0.0767 - val_accuracy: 0.9657\n",
            "Epoch 19/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9561 - val_loss: 0.0752 - val_accuracy: 0.9643\n",
            "Epoch 20/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9579 - val_loss: 0.0753 - val_accuracy: 0.9643\n",
            "Epoch 21/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9593 - val_loss: 0.0741 - val_accuracy: 0.9643\n",
            "Epoch 22/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9636 - val_loss: 0.0742 - val_accuracy: 0.9643\n",
            "Epoch 23/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9557 - val_loss: 0.0742 - val_accuracy: 0.9629\n",
            "Epoch 24/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9604 - val_loss: 0.0737 - val_accuracy: 0.9643\n",
            "Epoch 25/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9611 - val_loss: 0.0738 - val_accuracy: 0.9643\n",
            "Epoch 26/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9593 - val_loss: 0.0749 - val_accuracy: 0.9643\n",
            "Epoch 27/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9654 - val_loss: 0.0748 - val_accuracy: 0.9671\n",
            "Epoch 28/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9604 - val_loss: 0.0737 - val_accuracy: 0.9643\n",
            "Epoch 29/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9682 - val_loss: 0.0735 - val_accuracy: 0.9643\n",
            "Epoch 30/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9611 - val_loss: 0.0737 - val_accuracy: 0.9629\n",
            "Epoch 31/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9614 - val_loss: 0.0735 - val_accuracy: 0.9686\n",
            "Epoch 32/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9596 - val_loss: 0.0737 - val_accuracy: 0.9643\n",
            "Epoch 33/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9632 - val_loss: 0.0744 - val_accuracy: 0.9643\n",
            "Epoch 34/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9625 - val_loss: 0.0737 - val_accuracy: 0.9657\n",
            "Epoch 35/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9654 - val_loss: 0.0748 - val_accuracy: 0.9657\n",
            "Epoch 36/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9604 - val_loss: 0.0749 - val_accuracy: 0.9657\n",
            "Epoch 37/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1126 - accuracy: 0.9589 - val_loss: 0.0736 - val_accuracy: 0.9671\n",
            "Epoch 38/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9646 - val_loss: 0.0728 - val_accuracy: 0.9657\n",
            "Epoch 39/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9586 - val_loss: 0.0721 - val_accuracy: 0.9671\n",
            "Epoch 40/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9639 - val_loss: 0.0724 - val_accuracy: 0.9714\n",
            "Epoch 41/4000\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9629 - val_loss: 0.0727 - val_accuracy: 0.9700\n",
            "Epoch 42/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9629 - val_loss: 0.0726 - val_accuracy: 0.9686\n",
            "Epoch 43/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9643 - val_loss: 0.0734 - val_accuracy: 0.9700\n",
            "Epoch 44/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9629 - val_loss: 0.0730 - val_accuracy: 0.9657\n",
            "Epoch 45/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9682 - val_loss: 0.0734 - val_accuracy: 0.9700\n",
            "Epoch 46/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9625 - val_loss: 0.0732 - val_accuracy: 0.9671\n",
            "Epoch 47/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9629 - val_loss: 0.0730 - val_accuracy: 0.9700\n",
            "Epoch 48/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9646 - val_loss: 0.0732 - val_accuracy: 0.9700\n",
            "Epoch 49/4000\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9629 - val_loss: 0.0724 - val_accuracy: 0.9671\n",
            "Epoch 50/4000\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9621 - val_loss: 0.0719 - val_accuracy: 0.9700\n",
            "Epoch 51/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1058 - accuracy: 0.9689 - val_loss: 0.0712 - val_accuracy: 0.9700\n",
            "Epoch 52/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1011 - accuracy: 0.9618 - val_loss: 0.0719 - val_accuracy: 0.9700\n",
            "Epoch 53/4000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1015 - accuracy: 0.9646 - val_loss: 0.0722 - val_accuracy: 0.9686\n",
            "Epoch 54/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1033 - accuracy: 0.9650 - val_loss: 0.0720 - val_accuracy: 0.9700\n",
            "Epoch 55/4000\n",
            "88/88 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9625 - val_loss: 0.0715 - val_accuracy: 0.9686\n",
            "Epoch 56/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1035 - accuracy: 0.9604 - val_loss: 0.0720 - val_accuracy: 0.9643\n",
            "Epoch 57/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.0726 - val_accuracy: 0.9671\n",
            "Epoch 58/4000\n",
            "88/88 [==============================] - 1s 9ms/step - loss: 0.1022 - accuracy: 0.9618 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
            "Epoch 59/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9639 - val_loss: 0.0720 - val_accuracy: 0.9657\n",
            "Epoch 60/4000\n",
            "88/88 [==============================] - 1s 7ms/step - loss: 0.1037 - accuracy: 0.9643 - val_loss: 0.0716 - val_accuracy: 0.9657\n",
            "Epoch 61/4000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.0718 - val_accuracy: 0.9686\n",
            "Epoch 62/4000\n",
            "88/88 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9643 - val_loss: 0.0726 - val_accuracy: 0.9671\n",
            "Epoch 63/4000\n",
            "88/88 [==============================] - 1s 11ms/step - loss: 0.1036 - accuracy: 0.9607 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
            "Epoch 64/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9646 - val_loss: 0.0717 - val_accuracy: 0.9657\n",
            "Epoch 65/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9636 - val_loss: 0.0723 - val_accuracy: 0.9671\n",
            "Epoch 66/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9679 - val_loss: 0.0713 - val_accuracy: 0.9671\n",
            "Epoch 67/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9679 - val_loss: 0.0732 - val_accuracy: 0.9643\n",
            "Epoch 68/4000\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 0.0983 - accuracy: 0.9664 - val_loss: 0.0723 - val_accuracy: 0.9657\n",
            "Epoch 69/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9682 - val_loss: 0.0719 - val_accuracy: 0.9671\n",
            "Epoch 70/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0952 - accuracy: 0.9689 - val_loss: 0.0717 - val_accuracy: 0.9671\n",
            "Epoch 71/4000\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9643 - val_loss: 0.0719 - val_accuracy: 0.9657\n",
            "Epoch 71: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loss and training score \n",
        "model.evaluate(X_train,Y_train) #0.2= 0.8340799808502197\n",
        "#0.3= 0.8176583647727966"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipqnJUUUeR5Q",
        "outputId": "5f7c5678-69a9-4403-b9bb-bac9654d8f00"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07110144197940826, 0.9717857241630554]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing loss and testing score \n",
        "model.evaluate(X_val,Y_val) #0.2= 0.8176583647727966\n",
        "#0.3 =  0.831733822822570"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYQsyGlceXhQ",
        "outputId": "2ee149b4-7325-4ac4-c9ba-fe5a34a58d17"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07185523211956024, 0.9657142758369446]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#testing the model with 30% data \n",
        "Y_pred=model.predict(X_test).round(2) #gives the probability value of each class \n",
        "#for each row\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBg_z6HxehvJ",
        "outputId": "a9076f33-8410-423d-85ac-10eedf56c565"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  ],\n",
              "       [0.  ],\n",
              "       [0.  ],\n",
              "       ...,\n",
              "       [0.31],\n",
              "       [0.  ],\n",
              "       [0.27]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=np.where(Y_pred>=0.5,1,0)\n",
        "Y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL8MQp9WekXI",
        "outputId": "1f49c336-ff38-4bde-b057-b011db5ef289"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate classification report and confusion martix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "print(confusion_matrix(Y_test,Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W5FfLzmemON",
        "outputId": "4d85a609-c437-44ef-ba85-95968e9cb9d0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       751\n",
            "           1       0.99      0.97      0.98       750\n",
            "\n",
            "    accuracy                           0.98      1501\n",
            "   macro avg       0.98      0.98      0.98      1501\n",
            "weighted avg       0.98      0.98      0.98      1501\n",
            "\n",
            "[[741  10]\n",
            " [ 26 724]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  98 % accuracy "
      ],
      "metadata": {
        "id": "p8qbu1jre4ab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}